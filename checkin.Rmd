---
title: "Final Project Check-In"
author: "Ritika Iyer"
date: "4/26/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

```{load-packages, message = FALSE}
library(sf) 
library(tidyverse) 
library(knitr) 
library(readr)
library(stringr)

```

Regression methods are useful for estimating a relationship between two variables, x and y. Here, we treat x as the independent variable that has an estimated impact, measured through the regression method, on our dependent or outcome variable y. In bivariate regression models, x and y are the only relevant variables included, an the estimated impact of x on y is found in the 'coefficient' on the x-term. Equation 1 below shows an example of a bivariate model between x and y, where b is the coefficient that tells us the estimated impact of an increase in x on y. The error term, e, represents all other effects of variables that are not listed in the model. 

y = a + b(x) + e     (1)

However, bivariate models are most often subject to omitted variable bias, an issue that arises when additional variables that have an impact on y are not included in the model. Omitted variable bias results in a biased coefficient on x, or a biased b estimate. For this reason, multivariate models that include several x's rather than just the one of interest are generally preferred. 

In frequentist models of linear regression, like the one showed above, we are able to obtain point estimates of the relationship of interest. This paper will focus on another type of regression, Bayesian Linear Regression. The Bayesian method of regression estimates probability distributions rather than point estimates. Using a similar framework introduced in Equation 1 above, the Bayesian linear regression model estimates a distribution of outcomes for the output y sampled from a normal distribution of the x's included. Equation 2 below shows an example of this. 

y ~ N(bX,o^2I)      (2)


## Introduction to Bayesian Regression
As discussed above, the main goal of Bayesian Linear Regression is to determine the posterior distribution for the parameters in the model of interest. This is in contrast to frequentist regression models that seek to estimate a single value for each parameter that is considered the best estimate. In Bayesian models, the posterior probability of the parameters of interest are conditional upon prior probabilities of their inputs and outputs. Equation 3 below shows the fundamental expression of Bayes Theorem, which underlies the Bayesian regression method. 

Posterior = (Likelihood * Prior) / Normalization      (3)

In words, we can interpret Equation 3 as the following: the posterior distribution generated from a Bayesian regression model for the parameters is proportional to the likelihood of the parameters data times the prior probability of those parameters. Equation 4 below shows how we would start with a Bayesian mode, which assumes that the error term is independent and distributed as normal random variables are. 

y = α + βx + ϵ, i = 1,⋯,n     (4)

As compared to frequentist regression, there are a few main benefits of using a Bayesian regression model. Firstly, Bayesian regression leverages priors, which can include educated guesses for model parameters or estimates based on domain knowledge. This is helpful, because compared to frequentist models, we can actually utilize knowledge outside of the data itself to inform our predictions in a positive way. Even without helpful priors for all parameters, Bayesian regression allows us to use non-informative priors to improve our model, like assuming a normal distribution. The second benefit of Bayesian regression is that it allows us to quantify how uncertain we are about the model estimates, because it produces a distribution of possibilites for each parameter based on the data used and the priors assumed. Based on this, models using smaller data (i.e., with fewer data points) will result in a wider distribution. As the number of data points increases, the parameters converge closer to those estimated from OLS because the likelihood takes over the impact of the priors for each parameter. 

### Bayesian Regression and Public Policy
Bayesian regression can be a particularly interesting method to use to address public policy issues because of its ability to take into account prior information about the parameters of interest. Many policy problems are multi-faceted and evolve over time - as such, a single policy dataset is unlikely to be representative of all relevant information to the question at hand. Additionally, most policy solutions have nuance and may work differently across contexts. This dependence on context makes it hard to simply rely on point estimates as a meaningful way to design policy. For this reason, Bayesian methods that allow for the estimation of a posterior distribution, rather than a point estimate, can offer more to policymakers in terms of projected impact of a policy option. 


## Application of Bayesian Regression Methods
### Questions of Interest: 
Using Bayesian regression methods, I will estimate the impact of child health outcomes, like BMI, stunting status, and BMI-for-age z-score, on academic performance, measured by test scores in math and verbal subjects. Equations 5, 6, and 7 below show this. 

TEST SCORES = α + β(BMI) + CONTROLS + ϵ, where i = 1,⋯,n     (5)

TEST SCORES = α + β(BMI-for-Age Z Score) + CONTROLS + ϵ, where i = 1,⋯,n     (6)

TEST SCORES = α + β(Stunting Status) + CONTROLS + ϵ, where i = 1,⋯,n     (7)

In the above equations, "CONTROLS" refers to the parameters that will be included in the model as covariates and their respective coefficients/posterior distributions. These covariates are chosen based on whether they are expected to make up some of the variation in test scores (outside of the variation explained by the various independent variables of interest). We do this so that we can isolate the impact of the independent variable of interest on test scores, the dependent variable. Controls that will be included are mainly socioeconomic and demographic variables, like wealth, region, child age, access to services, etc. 

### Data Description
I will apply Bayesian regression to data from the Young Lives Project, a 15-year study of the changing nature of childhood poverty in Ethiopia, India (Andhra Pradesh and Telangana), Peru and Vietnam. I will specifically use a constructed longitudinal data set from India, with data collected every few years from 2002 to 2016. As a part of the Young Lives research project in India, 1,000 children were sampled for the older cohort (aged 7.5 to 8.5 years old at the start of the study) and 2,000 children were sampled for the younger cohort (aged 6 to 18 months old at the start of the study). I will use the younger cohort data for this analysis. The sampling methodology in the dataset of interest is multi-stage and randomly sampled, considered to be nationally representative. The individuals and their households within each cohort were visited five times, comprising five total rounds of data collection per child. The attrition is low, estimated at approximately 1.5 percent across rounds. 

I am  also curious as to how different, but relatively close sample sizes will impact the spread of the posterior distribution. Given that the younger cohort data set has approximately 2,000 students in it, I will test the relationship of interest on various groups of students (n = 100, 200, 500, 1000, 2000) to see how estimates change. In addition, I will estimate the model on the same children, but at different ages (using rounds 2 and 3 of data collection) to see if there is a differential estimated impact by age.

### Application of Methods
```{load-data, message = FALSE}
setwd("Users/ritikaiyer/data/project")

younglives <- read_csv("project/projectdata.csv") 
```

### Sources: 
https://towardsdatascience.com/introduction-to-bayesian-linear-regression-e66e60791ea7

https://statswithr.github.io/book/introduction-to-bayesian-regression.html 

https://www.younglives.org.uk

### Next Steps:
1. Build out mathematical explanation of Bayesian Regression (with equations and proof)
2. Improve literature review (diversify sources, add in historical perspective)
3. Apply methods to example of interest after better determining priors for each parameter. I want to better understand if other years of data can be used as priors for the years used in the analysis (i.e., using data in the file from Rounds 1 and 2 as informative to the model application that uses data from Round 3 exclusively).
